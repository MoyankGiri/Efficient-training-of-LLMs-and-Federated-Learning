# Efficient-training-of-LLMs-and-Federated-Learning
Scalable &amp; efficient training for deep learning &amp; LLMs. ðŸš€ Features a Hybrid Split Federated Learning framework with caching (96Ã— compute &amp; 4.5Ã— comm. savings), plus a dynamic fine-tuning strategy using LoRA &amp; selective layers, cutting time &amp; GPU use for LLMs.
